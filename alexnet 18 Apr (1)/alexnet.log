_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
activation_1 (Activation)    (None, 55, 55, 96)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   
_________________________________________________________________
activation_2 (Activation)    (None, 17, 17, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    
_________________________________________________________________
activation_3 (Activation)    (None, 6, 6, 384)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   
_________________________________________________________________
activation_4 (Activation)    (None, 4, 4, 384)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    
_________________________________________________________________
activation_5 (Activation)    (None, 2, 2, 256)         0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              1052672   
_________________________________________________________________
activation_6 (Activation)    (None, 4096)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
activation_7 (Activation)    (None, 4096)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 1000)              4097000   
_________________________________________________________________
activation_8 (Activation)    (None, 1000)              0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 1000)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 2002      
_________________________________________________________________
activation_9 (Activation)    (None, 2)                 0         
=================================================================
Total params: 28,039,482
Trainable params: 28,039,482
Non-trainable params: 0
_________________________________________________________________
Train on 8348 samples, validate on 928 samples
Epoch 1/50
36s - loss: 0.6492 - acc: 0.6597 - val_loss: 0.7747 - val_acc: 0.4957
Epoch 2/50
33s - loss: 0.6397 - acc: 0.6651 - val_loss: 0.7741 - val_acc: 0.4957
Epoch 3/50
33s - loss: 0.6414 - acc: 0.6651 - val_loss: 0.7551 - val_acc: 0.4957
Epoch 4/50
33s - loss: 0.6395 - acc: 0.6651 - val_loss: 0.7603 - val_acc: 0.4957
Epoch 5/50
33s - loss: 0.6393 - acc: 0.6651 - val_loss: 0.7409 - val_acc: 0.4957
Epoch 6/50
33s - loss: 0.6394 - acc: 0.6651 - val_loss: 0.7392 - val_acc: 0.4957
Epoch 7/50
33s - loss: 0.6390 - acc: 0.6651 - val_loss: 0.7421 - val_acc: 0.4957
Epoch 8/50
33s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7545 - val_acc: 0.4957
Epoch 9/50
33s - loss: 0.6391 - acc: 0.6651 - val_loss: 0.7524 - val_acc: 0.4957
Epoch 10/50
33s - loss: 0.6387 - acc: 0.6651 - val_loss: 0.7574 - val_acc: 0.4957
Epoch 11/50
33s - loss: 0.6383 - acc: 0.6651 - val_loss: 0.7475 - val_acc: 0.4957
Epoch 12/50
33s - loss: 0.6383 - acc: 0.6651 - val_loss: 0.7343 - val_acc: 0.4957
Epoch 13/50
33s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7359 - val_acc: 0.4957
Epoch 14/50
33s - loss: 0.6387 - acc: 0.6651 - val_loss: 0.7489 - val_acc: 0.4957
Epoch 15/50
33s - loss: 0.6383 - acc: 0.6651 - val_loss: 0.7569 - val_acc: 0.4957
Epoch 16/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7405 - val_acc: 0.4957
Epoch 17/50
33s - loss: 0.6381 - acc: 0.6651 - val_loss: 0.7493 - val_acc: 0.4957
Epoch 18/50
33s - loss: 0.6386 - acc: 0.6651 - val_loss: 0.7697 - val_acc: 0.4957
Epoch 19/50
33s - loss: 0.6387 - acc: 0.6651 - val_loss: 0.7585 - val_acc: 0.4957
Epoch 20/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7415 - val_acc: 0.4957
Epoch 21/50
33s - loss: 0.6385 - acc: 0.6651 - val_loss: 0.7544 - val_acc: 0.4957
Epoch 22/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7575 - val_acc: 0.4957
Epoch 23/50
33s - loss: 0.6375 - acc: 0.6651 - val_loss: 0.7432 - val_acc: 0.4957
Epoch 24/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7495 - val_acc: 0.4957
Epoch 25/50
33s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7566 - val_acc: 0.4957
Epoch 26/50
32s - loss: 0.6378 - acc: 0.6651 - val_loss: 0.7528 - val_acc: 0.4957
Epoch 27/50
32s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7468 - val_acc: 0.4957
Epoch 28/50
33s - loss: 0.6385 - acc: 0.6651 - val_loss: 0.7569 - val_acc: 0.4957
Epoch 29/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7442 - val_acc: 0.4957
Epoch 30/50
33s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7457 - val_acc: 0.4957
Epoch 31/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7548 - val_acc: 0.4957
Epoch 32/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7535 - val_acc: 0.4957
Epoch 33/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7484 - val_acc: 0.4957
Epoch 34/50
33s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7536 - val_acc: 0.4957
Epoch 35/50
32s - loss: 0.6381 - acc: 0.6651 - val_loss: 0.7523 - val_acc: 0.4957
Epoch 36/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7500 - val_acc: 0.4957
Epoch 37/50
33s - loss: 0.6376 - acc: 0.6651 - val_loss: 0.7462 - val_acc: 0.4957
Epoch 38/50
33s - loss: 0.6378 - acc: 0.6651 - val_loss: 0.7526 - val_acc: 0.4957
Epoch 39/50
32s - loss: 0.6382 - acc: 0.6651 - val_loss: 0.7564 - val_acc: 0.4957
Epoch 40/50
32s - loss: 0.6385 - acc: 0.6651 - val_loss: 0.7525 - val_acc: 0.4957
Epoch 41/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7509 - val_acc: 0.4957
Epoch 42/50
33s - loss: 0.6376 - acc: 0.6651 - val_loss: 0.7581 - val_acc: 0.4957
Epoch 43/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7513 - val_acc: 0.4957
Epoch 44/50
33s - loss: 0.6378 - acc: 0.6651 - val_loss: 0.7500 - val_acc: 0.4957
Epoch 45/50
33s - loss: 0.6377 - acc: 0.6651 - val_loss: 0.7556 - val_acc: 0.4957
Epoch 46/50
33s - loss: 0.6378 - acc: 0.6651 - val_loss: 0.7518 - val_acc: 0.4957
Epoch 47/50
33s - loss: 0.6380 - acc: 0.6651 - val_loss: 0.7514 - val_acc: 0.4957
Epoch 48/50
33s - loss: 0.6381 - acc: 0.6651 - val_loss: 0.7545 - val_acc: 0.4957
Epoch 49/50
33s - loss: 0.6379 - acc: 0.6651 - val_loss: 0.7501 - val_acc: 0.4957
Epoch 50/50
33s - loss: 0.6376 - acc: 0.6651 - val_loss: 0.7495 - val_acc: 0.4957
