_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     
_________________________________________________________________
activation_1 (Activation)    (None, 55, 55, 96)        0         
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 17, 17, 256)       2973952   
_________________________________________________________________
activation_2 (Activation)    (None, 17, 17, 256)       0         
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 8, 8, 256)         0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    
_________________________________________________________________
activation_3 (Activation)    (None, 6, 6, 384)         0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   
_________________________________________________________________
activation_4 (Activation)    (None, 4, 4, 384)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 2, 256)         884992    
_________________________________________________________________
activation_5 (Activation)    (None, 2, 2, 256)         0         
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 4096)              1052672   
_________________________________________________________________
activation_6 (Activation)    (None, 4096)              0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 4096)              16781312  
_________________________________________________________________
activation_7 (Activation)    (None, 4096)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4096)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 1000)              4097000   
_________________________________________________________________
activation_8 (Activation)    (None, 1000)              0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 1000)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 2)                 2002      
_________________________________________________________________
activation_9 (Activation)    (None, 2)                 0         
=================================================================
Total params: 28,039,482
Trainable params: 28,039,482
Non-trainable params: 0
_________________________________________________________________
Train on 9276 samples, validate on 326 samples
Epoch 1/50
35s - loss: 0.6616 - acc: 0.6421 - val_loss: 0.6812 - val_acc: 0.6043
Epoch 2/50
34s - loss: 0.6510 - acc: 0.6481 - val_loss: 0.6743 - val_acc: 0.6043
Epoch 3/50
33s - loss: 0.6501 - acc: 0.6481 - val_loss: 0.6774 - val_acc: 0.6043
Epoch 4/50
33s - loss: 0.6506 - acc: 0.6481 - val_loss: 0.6720 - val_acc: 0.6043
Epoch 5/50
33s - loss: 0.6495 - acc: 0.6481 - val_loss: 0.6722 - val_acc: 0.6043
Epoch 6/50
34s - loss: 0.6494 - acc: 0.6481 - val_loss: 0.6774 - val_acc: 0.6043
Epoch 7/50
35s - loss: 0.6503 - acc: 0.6481 - val_loss: 0.6731 - val_acc: 0.6043
Epoch 8/50
35s - loss: 0.6496 - acc: 0.6481 - val_loss: 0.6781 - val_acc: 0.6043
Epoch 9/50
35s - loss: 0.6492 - acc: 0.6481 - val_loss: 0.6748 - val_acc: 0.6043
Epoch 10/50
33s - loss: 0.6496 - acc: 0.6481 - val_loss: 0.6779 - val_acc: 0.6043
Epoch 11/50
34s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6734 - val_acc: 0.6043
Epoch 12/50
35s - loss: 0.6495 - acc: 0.6481 - val_loss: 0.6734 - val_acc: 0.6043
Epoch 13/50
35s - loss: 0.6492 - acc: 0.6481 - val_loss: 0.6734 - val_acc: 0.6043
Epoch 14/50
33s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6750 - val_acc: 0.6043
Epoch 15/50
32s - loss: 0.6490 - acc: 0.6481 - val_loss: 0.6774 - val_acc: 0.6043
Epoch 16/50
33s - loss: 0.6495 - acc: 0.6481 - val_loss: 0.6769 - val_acc: 0.6043
Epoch 17/50
34s - loss: 0.6495 - acc: 0.6481 - val_loss: 0.6735 - val_acc: 0.6043
Epoch 18/50
34s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6761 - val_acc: 0.6043
Epoch 19/50
33s - loss: 0.6489 - acc: 0.6481 - val_loss: 0.6745 - val_acc: 0.6043
Epoch 20/50
32s - loss: 0.6492 - acc: 0.6481 - val_loss: 0.6761 - val_acc: 0.6043
Epoch 21/50
32s - loss: 0.6494 - acc: 0.6481 - val_loss: 0.6734 - val_acc: 0.6043
Epoch 22/50
33s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6746 - val_acc: 0.6043
Epoch 23/50
34s - loss: 0.6494 - acc: 0.6481 - val_loss: 0.6735 - val_acc: 0.6043
Epoch 24/50
34s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6731 - val_acc: 0.6043
Epoch 25/50
34s - loss: 0.6486 - acc: 0.6481 - val_loss: 0.6775 - val_acc: 0.6043
Epoch 26/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6757 - val_acc: 0.6043
Epoch 27/50
35s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6758 - val_acc: 0.6043
Epoch 28/50
34s - loss: 0.6493 - acc: 0.6481 - val_loss: 0.6751 - val_acc: 0.6043
Epoch 29/50
34s - loss: 0.6485 - acc: 0.6481 - val_loss: 0.6759 - val_acc: 0.6043
Epoch 30/50
34s - loss: 0.6491 - acc: 0.6481 - val_loss: 0.6747 - val_acc: 0.6043
Epoch 31/50
35s - loss: 0.6489 - acc: 0.6481 - val_loss: 0.6755 - val_acc: 0.6043
Epoch 32/50
33s - loss: 0.6492 - acc: 0.6481 - val_loss: 0.6755 - val_acc: 0.6043
Epoch 33/50
32s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6742 - val_acc: 0.6043
Epoch 34/50
32s - loss: 0.6486 - acc: 0.6481 - val_loss: 0.6750 - val_acc: 0.6043
Epoch 35/50
33s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6740 - val_acc: 0.6043
Epoch 36/50
33s - loss: 0.6489 - acc: 0.6481 - val_loss: 0.6774 - val_acc: 0.6043
Epoch 37/50
34s - loss: 0.6489 - acc: 0.6481 - val_loss: 0.6753 - val_acc: 0.6043
Epoch 38/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6747 - val_acc: 0.6043
Epoch 39/50
35s - loss: 0.6490 - acc: 0.6481 - val_loss: 0.6762 - val_acc: 0.6043
Epoch 40/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6761 - val_acc: 0.6043
Epoch 41/50
35s - loss: 0.6487 - acc: 0.6481 - val_loss: 0.6741 - val_acc: 0.6043
Epoch 42/50
35s - loss: 0.6492 - acc: 0.6481 - val_loss: 0.6751 - val_acc: 0.6043
Epoch 43/50
35s - loss: 0.6486 - acc: 0.6481 - val_loss: 0.6748 - val_acc: 0.6043
Epoch 44/50
35s - loss: 0.6489 - acc: 0.6481 - val_loss: 0.6738 - val_acc: 0.6043
Epoch 45/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6764 - val_acc: 0.6043
Epoch 46/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6750 - val_acc: 0.6043
Epoch 47/50
34s - loss: 0.6486 - acc: 0.6481 - val_loss: 0.6740 - val_acc: 0.6043
Epoch 48/50
33s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6765 - val_acc: 0.6043
Epoch 49/50
34s - loss: 0.6487 - acc: 0.6481 - val_loss: 0.6740 - val_acc: 0.6043
Epoch 50/50
35s - loss: 0.6488 - acc: 0.6481 - val_loss: 0.6746 - val_acc: 0.6043
